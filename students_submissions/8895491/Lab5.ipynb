{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name - Shreshth Sinha\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student ID - 8895491"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, r2_score\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diabetes = load_diabetes()\n",
    "X, y = df_diabetes.data, df_diabetes.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spliting Data set into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees = range(9) \n",
    "results = []\n",
    "\n",
    "for degree in degrees:\n",
    "    md = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
    "    md.fit(X_train, y_train)\n",
    "    y_pred = md.predict(X_test)\n",
    "    \n",
    "    # We will calculate the r2 score\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    # We will calculate the mean absolute error score\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    \n",
    "    # We will calculate the mean absolute percentage error score\n",
    "    mape = mean_absolute_percentage_error(y_test, y_pred) \n",
    "    \n",
    "    results.append((degree, r2, mae, mape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = pd.DataFrame(results, columns=['Degree', 'R-Squared', 'MAE', 'MAPE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating mean and standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary Table:\n",
      "         R-Squared             MAE          MAPE    \n",
      "             mean std        mean std      mean std\n",
      "Degree                                             \n",
      "0       -0.011963 NaN   64.006461 NaN  0.627918 NaN\n",
      "1        0.452603 NaN   42.794095 NaN  0.374998 NaN\n",
      "2        0.415640 NaN   43.581693 NaN  0.382857 NaN\n",
      "3      -15.627261 NaN  179.775281 NaN  1.637362 NaN\n",
      "4      -26.728083 NaN  261.667144 NaN  2.300991 NaN\n",
      "5      -25.992920 NaN  255.968358 NaN  2.270202 NaN\n",
      "6      -25.975743 NaN  255.908618 NaN  2.269658 NaN\n",
      "7      -25.975503 NaN  255.906927 NaN  2.269650 NaN\n",
      "8      -25.975482 NaN  255.906853 NaN  2.269649 NaN\n"
     ]
    }
   ],
   "source": [
    "mn_std_df = df_res.groupby('Degree').agg({\n",
    "    'R-Squared': ['mean', 'std'],\n",
    "    'MAE': ['mean', 'std'],\n",
    "    'MAPE': ['mean', 'std']\n",
    "})\n",
    "\n",
    "# We will display the summary table\n",
    "print(\"Summary Table:\\n\",mn_std_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The summary table indicates that there is only one data point (NaN) for each degree that can be evaluated. This may be the result of certain dataset characteristics or may be based on how the data is split during the cross-validation process. For some particular degrees, the data may be extremely scarce. The following are possible causes:\n",
    "1.The best model recognition: R-square, MAE, and MAPE measures allow us to determine which model will exhibit the highest performance. We can see that the model with degree 1 (quadratic polynomial) has the highest R-squared (0.45) and the lowest MAE (42.79) and MAPE (0.37) based on the mean R-Squared, MAE, and MAPE metrics. As a result, polynomial models can be seen performing well\n",
    "\n",
    "Why we selected that particular model (Degree 1):\n",
    "R-Squared: This degree 1 model has the greatest R-Squared value, which shows that it explains a considerable amount of the data's variance. This indicates that the quadratic model fits the data significantly more effectively.\n",
    "\n",
    "Mean Absolute Error (MAE) and Mean Absolute Percentage Error (MAPE): The model with degree 1 also has the lowest MAE and MAPE. This shows that, in terms of predictive accuracy, it has the smallest average absolute difference between projected and actual values.\n",
    " \n",
    "2.Additional evaluation and interpretation of the performance of the models:  \n",
    "If an analysis can offer at least one useful insight regarding the selection of the best model, or about features of the chosen one (for example, taking into account an analysis of when it is failing), then the insights for the necessary metrics can be investigated further. It is also crucial to notice that the R-Squared values are perceived as notably negative for higher degree models (for example, degrees 3 to 8). This shows how poorly these models are performing and suggests that they may have overfitted to the training set. This is a result of the models, which develop into very sophisticated representations of the data noise.\n",
    "\n",
    "As a result, the quadratic model (degree 1) is advised for use in making predictions since it exhibits a good balance between model complexity and predictive ability. When selecting a final model, it is necessary to take into account additional aspects like interpretability and computational resources. Regularised regression is one of the more sophisticated approaches that can be useful for additional investigation.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cscn8010",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
